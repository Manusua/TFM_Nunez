{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in c:\\users\\anune\\anaconda3\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\anune\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=1.1.1 in c:\\users\\anune\\anaconda3\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.17.3 in c:\\users\\anune\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.5.0 in c:\\users\\anune\\anaconda3\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Puntuación de la regresión lineal: 0.5496551271709036\n",
      "Parámetros de entrada:\n",
      "               mf         M           t             p           LHV        bpr  \\\n",
      "521  1383.299341  0.394352  283.614915  86302.984076  4.303808e+07   9.701351   \n",
      "737  1415.262118  0.383073  268.621519  86889.983840  3.994584e+07  10.076256   \n",
      "740  1473.049259  0.381253  280.708807  92496.954307  4.431118e+07   9.653684   \n",
      "660  1449.448941  0.401908  280.956805  90660.513194  4.360290e+07   9.360587   \n",
      "411  1454.161152  0.398929  285.151774  88737.468425  4.617217e+07   9.348216   \n",
      "..           ...       ...         ...           ...           ...        ...   \n",
      "408  1404.442077  0.415226  273.660916  88729.896648  4.034315e+07   9.507704   \n",
      "332  1490.071900  0.409244  284.929797  92650.925686  4.145547e+07   9.415299   \n",
      "208  1399.607068  0.383402  289.119347  91521.039806  4.623200e+07   9.403146   \n",
      "613  1464.611219  0.415987  269.594861  94166.511075  4.227834e+07  10.048646   \n",
      "78   1485.308093  0.413878  276.349533  92701.066544  4.271026e+07   9.747151   \n",
      "\n",
      "       eta_fn    eta_c1    eta_c2    eta_t1    eta_t2     eta_n    eta_cc  \\\n",
      "521  0.963630  0.886648  0.881578  0.922325  0.927238  0.986601  1.003271   \n",
      "737  0.934071  0.907229  0.927913  0.866910  0.895340  0.915898  0.978774   \n",
      "740  0.932378  0.892028  0.881119  0.884737  0.889713  0.921064  0.984128   \n",
      "660  0.960129  0.891352  0.886317  0.893067  0.901779  0.944661  0.978948   \n",
      "411  0.933389  0.870134  0.884853  0.860949  0.911880  0.925777  0.924109   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "408  0.891178  0.870885  0.846246  0.850074  0.887998  0.917611  0.995176   \n",
      "332  0.893153  0.861156  0.890744  0.905747  0.919978  0.918864  0.933753   \n",
      "208  0.958771  0.895247  0.930635  0.929590  0.900631  0.914216  0.922742   \n",
      "613  0.877311  0.894907  0.851061  0.868792  0.864111  0.974971  0.924245   \n",
      "78   0.902887  0.890107  0.915485  0.860917  0.908506  0.913679  0.961482   \n",
      "\n",
      "         PI_i     PI_fn     PI_c1      PI_c2     PI_cc  \n",
      "521  0.997500  1.608085  1.566424  10.145176  0.962016  \n",
      "737  0.983602  1.531414  1.521357   9.502534  0.941610  \n",
      "740  1.021337  1.549908  1.560833   9.971984  1.026410  \n",
      "660  1.009998  1.525464  1.489591   9.596623  1.007121  \n",
      "411  1.027537  1.585334  1.517542   9.925869  0.985114  \n",
      "..        ...       ...       ...        ...       ...  \n",
      "408  0.999180  1.584567  1.566235  10.006203  1.025470  \n",
      "332  0.993903  1.572064  1.492983   9.915835  0.961731  \n",
      "208  1.027439  1.530471  1.509612  10.149823  0.985325  \n",
      "613  0.996423  1.576506  1.598817   9.920193  0.984419  \n",
      "78   1.028158  1.605247  1.481093   9.977321  1.010458  \n",
      "\n",
      "[200 rows x 18 columns]\n",
      "Predicciones de la regresión lineal:\n",
      " [6.46471444 4.20168099 6.77916787 6.69848725 5.41088915 5.09063714\n",
      " 6.26635642 5.39271513 6.31567055 5.11225925 6.25646067 4.59266705\n",
      " 5.21527519 5.1914026  7.78890232 7.45079679 5.40896523 8.97980349\n",
      " 5.07706038 9.72554027 5.12534449 5.31403366 3.84642562 6.62002391\n",
      " 5.77809101 5.23655268 5.00591393 4.2469253  6.62001354 4.05105212\n",
      " 7.99690308 6.36261555 5.62907693 7.29415525 6.34658454 6.22447777\n",
      " 5.65523906 7.41290853 4.35241627 6.30317502 5.42061727 5.6472905\n",
      " 4.92087371 5.00259849 6.66980341 9.02273941 4.92778307 7.67517748\n",
      " 6.8169413  6.30710469 6.56906621 4.78387821 9.22567225 6.70539514\n",
      " 5.89770957 6.31684576 4.5241165  4.92378886 5.65742051 7.56152446\n",
      " 7.17199613 6.28783511 7.70560974 6.47713084 4.26066266 4.17119031\n",
      " 6.11642791 7.01954309 8.06938831 5.08142189 5.70137072 7.20594365\n",
      " 6.76483994 7.54793386 5.65259929 4.80113029 5.2168555  8.3951828\n",
      " 4.23515315 4.79793493 4.0791175  6.82193121 5.5851876  6.40111256\n",
      " 4.15340697 4.7951242  6.52909017 8.26570437 7.20051577 5.47978276\n",
      " 7.63492375 6.80013368 4.51608468 4.291217   7.76423826 5.80212917\n",
      " 6.51748428 6.65819838 7.76726626 7.22425689 7.6750454  6.58268897\n",
      " 5.52442033 6.1347038  5.316685   4.01069861 6.24456537 4.79658296\n",
      " 4.60477726 7.7810832  7.30966339 7.28469345 6.50983062 6.99735208\n",
      " 5.26249082 8.77027122 5.59380561 4.67900908 4.63714104 4.94149207\n",
      " 4.41568198 7.14037082 7.14053852 4.67471012 4.36023688 6.62269371\n",
      " 5.42671195 5.60959015 7.15790379 8.02533409 5.38573294 5.62556755\n",
      " 7.99873582 6.32906323 5.51292837 6.59924984 4.82072931 5.22101256\n",
      " 7.79880006 7.40628453 8.02657489 5.66292705 5.77855395 5.30477067\n",
      " 7.09159932 4.77114308 6.38431596 5.284463   5.63618163 6.15920845\n",
      " 5.10712241 4.48286097 7.00150586 4.27182087 5.88538964 5.57626771\n",
      " 6.77439011 5.62982666 4.25115967 5.74299718 4.73657011 6.19006257\n",
      " 6.61438149 6.37606888 8.07481325 5.74934527 5.67876418 7.76000318\n",
      " 8.7004136  5.64155795 7.24043692 6.07688312 5.79616105 5.49545641\n",
      " 4.36789338 4.57464051 6.78656932 6.54537498 6.70591363 6.42785724\n",
      " 8.64793792 4.28575348 5.17630953 5.07407811 5.23218896 6.04279661\n",
      " 5.23013856 8.41592527 5.64308631 6.34600473 6.60746928 6.15069277\n",
      " 6.67086565 6.6568596  5.8371766  4.86412382 6.23111832 7.1607774\n",
      " 3.74312544 5.72639574]\n",
      "Error Cuadrático Medio (ECM): 1.1149708795440878\n",
      "Error Absoluto Medio (EAM): 0.8110552685580873\n",
      "Coeficiente de Pendiente: [ 4.17661951e-03  5.71200023e-01  9.71959741e-02  1.50719378e-05\n",
      "  2.64765023e-08 -5.99616372e-01 -6.66611025e+00  1.87721250e+01\n",
      "  6.42114753e+00  1.54422155e+01  1.67920868e+01 -5.45881618e-01\n",
      "  1.09493034e+01 -2.04771634e+00 -3.97192727e+00  2.78407463e+00\n",
      " -3.00785220e-01  1.44908533e+01]\n",
      "Coeficiente de Intercepto: -86.68850820165552\n",
      "Coeficiente de determinación (R^2) de las predicciones: 0.5496551271709036\n"
     ]
    }
   ],
   "source": [
    "# Algoritmo de Regresión Lineal\n",
    "!pip install --upgrade scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from datetime import datetime\n",
    "\n",
    "fecha_actual = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "archivo = f'datos_{fecha_actual}_ia.csv'\n",
    "\n",
    "def aplicar_modelo_regresion(csv_file):\n",
    "    # Cargar datos desde el archivo CSV\n",
    "    datos = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Dividir los datos en características (X) y etiquetas (y) para la regresión\n",
    "    X_regresion = datos.iloc[:, :-1]  # Selecciona todas las filas y todas las columnas excepto la última\n",
    "    y_regresion = datos.iloc[:, -1] # Selecciona todas las filas y la última columna\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba para regresión\n",
    "    X_train_regresion, X_test_regresion, y_train_regresion, y_test_regresion = train_test_split(X_regresion, y_regresion, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Inicializar y entrenar el modelo de regresión lineal\n",
    "    modelo_regresion = LinearRegression()\n",
    "    modelo_regresion.fit(X_train_regresion, y_train_regresion)\n",
    "\n",
    "    # Evaluar el rendimiento del modelo de regresión\n",
    "    puntuacion_regresion = modelo_regresion.score(X_test_regresion, y_test_regresion)\n",
    "    \n",
    "    # Realizar predicciones en el conjunto de prueba\n",
    "    predicciones = modelo_regresion.predict(X_test_regresion)\n",
    "    \n",
    "    # Calcular el Error Cuadrático Medio (ECM)\n",
    "    ecm = mean_squared_error(y_test_regresion, predicciones)\n",
    "\n",
    "    # Calcular el Error Absoluto Medio (EAM)\n",
    "    eam = mean_absolute_error(y_test_regresion, predicciones)\n",
    "\n",
    "    # Coeficientes de Regresión (pendiente e intercepto)\n",
    "    pendiente = modelo_regresion.coef_\n",
    "    intercepto = modelo_regresion.intercept_\n",
    "    \n",
    "    # Coeficiente de determinación R2 \n",
    "    r2 = r2_score(y_test_regresion, predicciones)\n",
    "    \n",
    "    return puntuacion_regresion, predicciones, y_train_regresion, y_test_regresion, X_train_regresion, X_test_regresion, ecm, eam, pendiente, intercepto, r2\n",
    "\n",
    "# Aplicar modelo regresión\n",
    "puntuacion_regresion, predicciones, y_train_regresion, y_test_regresion, X_train_regresion, X_test_regresion, ecm, eam, pendiente, intercepto, r2 = aplicar_modelo_regresion(archivo)\n",
    "\n",
    "# Mostrar las predicciones y la puntuacion\n",
    "print(\"Puntuación de la regresión lineal:\", puntuacion_regresion)\n",
    "print(\"Parámetros de entrada:\\n\", X_test_regresion)\n",
    "print(\"Predicciones de la regresión lineal:\\n\", predicciones)\n",
    "print(\"Error Cuadrático Medio (ECM):\", ecm)\n",
    "print(\"Error Absoluto Medio (EAM):\", eam)\n",
    "print(\"Coeficiente de Pendiente:\", pendiente)\n",
    "print(\"Coeficiente de Intercepto:\", intercepto)\n",
    "print(\"Coeficiente de determinación (R^2) de las predicciones:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in c:\\users\\anune\\anaconda3\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.17.3 in c:\\users\\anune\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.5.0 in c:\\users\\anune\\anaconda3\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=1.1.1 in c:\\users\\anune\\anaconda3\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\anune\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Puntuación del modelo de regresión múltiple (Random Forest): 0.552785028553257\n",
      "Parámetros de entrada:\n",
      "               mf         M           t             p           LHV        bpr  \\\n",
      "521  1383.299341  0.394352  283.614915  86302.984076  4.303808e+07   9.701351   \n",
      "737  1415.262118  0.383073  268.621519  86889.983840  3.994584e+07  10.076256   \n",
      "740  1473.049259  0.381253  280.708807  92496.954307  4.431118e+07   9.653684   \n",
      "660  1449.448941  0.401908  280.956805  90660.513194  4.360290e+07   9.360587   \n",
      "411  1454.161152  0.398929  285.151774  88737.468425  4.617217e+07   9.348216   \n",
      "..           ...       ...         ...           ...           ...        ...   \n",
      "408  1404.442077  0.415226  273.660916  88729.896648  4.034315e+07   9.507704   \n",
      "332  1490.071900  0.409244  284.929797  92650.925686  4.145547e+07   9.415299   \n",
      "208  1399.607068  0.383402  289.119347  91521.039806  4.623200e+07   9.403146   \n",
      "613  1464.611219  0.415987  269.594861  94166.511075  4.227834e+07  10.048646   \n",
      "78   1485.308093  0.413878  276.349533  92701.066544  4.271026e+07   9.747151   \n",
      "\n",
      "       eta_fn    eta_c1    eta_c2    eta_t1    eta_t2     eta_n    eta_cc  \\\n",
      "521  0.963630  0.886648  0.881578  0.922325  0.927238  0.986601  1.003271   \n",
      "737  0.934071  0.907229  0.927913  0.866910  0.895340  0.915898  0.978774   \n",
      "740  0.932378  0.892028  0.881119  0.884737  0.889713  0.921064  0.984128   \n",
      "660  0.960129  0.891352  0.886317  0.893067  0.901779  0.944661  0.978948   \n",
      "411  0.933389  0.870134  0.884853  0.860949  0.911880  0.925777  0.924109   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "408  0.891178  0.870885  0.846246  0.850074  0.887998  0.917611  0.995176   \n",
      "332  0.893153  0.861156  0.890744  0.905747  0.919978  0.918864  0.933753   \n",
      "208  0.958771  0.895247  0.930635  0.929590  0.900631  0.914216  0.922742   \n",
      "613  0.877311  0.894907  0.851061  0.868792  0.864111  0.974971  0.924245   \n",
      "78   0.902887  0.890107  0.915485  0.860917  0.908506  0.913679  0.961482   \n",
      "\n",
      "         PI_i     PI_fn     PI_c1      PI_c2     PI_cc  \n",
      "521  0.997500  1.608085  1.566424  10.145176  0.962016  \n",
      "737  0.983602  1.531414  1.521357   9.502534  0.941610  \n",
      "740  1.021337  1.549908  1.560833   9.971984  1.026410  \n",
      "660  1.009998  1.525464  1.489591   9.596623  1.007121  \n",
      "411  1.027537  1.585334  1.517542   9.925869  0.985114  \n",
      "..        ...       ...       ...        ...       ...  \n",
      "408  0.999180  1.584567  1.566235  10.006203  1.025470  \n",
      "332  0.993903  1.572064  1.492983   9.915835  0.961731  \n",
      "208  1.027439  1.530471  1.509612  10.149823  0.985325  \n",
      "613  0.996423  1.576506  1.598817   9.920193  0.984419  \n",
      "78   1.028158  1.605247  1.481093   9.977321  1.010458  \n",
      "\n",
      "[200 rows x 18 columns]\n",
      "Predicciones del modelo de regresión múltiple (Random Forest):\n",
      " [6.448  4.762  6.9316 7.1594 5.9351 5.005  6.8262 6.019  5.7283 4.5098\n",
      " 5.71   5.2419 5.722  5.5868 6.739  7.2884 5.044  7.8084 5.2779 8.2853\n",
      " 6.4633 4.897  3.4629 7.1746 5.689  6.1542 5.8213 4.486  6.799  4.237\n",
      " 6.8957 6.2769 5.9441 7.0334 6.157  5.7338 6.8859 7.5771 4.654  6.1933\n",
      " 5.074  5.68   5.515  4.927  6.6881 8.1651 5.29   7.0001 6.9977 5.674\n",
      " 6.7452 5.7429 8.4295 7.0032 4.84   5.8361 5.4249 4.954  6.1422 7.3368\n",
      " 6.8773 6.5111 7.6602 6.7992 4.9328 4.618  6.334  6.8115 7.0482 5.7038\n",
      " 5.893  6.4782 6.9019 8.0358 6.139  5.1431 5.1999 7.8768 5.041  5.473\n",
      " 4.0059 5.632  5.59   6.5952 4.339  4.999  5.941  7.5079 7.2284 5.89\n",
      " 7.5255 6.6976 4.5488 4.813  6.8561 6.8564 5.9286 6.7841 7.267  6.4785\n",
      " 7.0422 7.0426 6.409  5.242  6.5531 4.852  5.458  5.668  5.104  8.282\n",
      " 7.0902 7.0395 4.2278 7.0485 6.043  6.9823 6.172  4.96   5.236  5.5931\n",
      " 3.757  6.7724 7.6758 4.438  4.948  5.719  5.8151 5.854  7.1806 6.8772\n",
      " 4.4198 5.389  7.7232 5.4972 4.345  5.8781 5.731  5.71   7.3099 7.357\n",
      " 7.3546 6.0431 5.848  6.4721 6.3579 4.6839 5.968  5.374  5.6381 6.8592\n",
      " 4.564  4.534  6.835  4.945  5.9502 5.692  6.9493 5.4189 4.7499 6.1751\n",
      " 6.0071 6.2171 5.164  6.5082 7.4507 5.44   6.1811 7.3098 8.1053 4.843\n",
      " 6.0583 4.915  5.533  6.4002 4.6689 4.882  7.0602 6.4601 5.842  6.2532\n",
      " 7.7659 4.2129 6.046  5.008  6.1031 6.739  5.239  7.7658 5.104  6.136\n",
      " 5.1907 5.9681 6.8264 6.754  5.77   5.023  6.9223 6.8625 4.114  6.2381]\n",
      "Error Cuadrático Medio (ECM): 1.1072218207499998\n",
      "Error Absoluto Medio (EAM): 0.8341284999999999\n",
      "Importancia de las características: [0.03519184 0.02114923 0.2681396  0.02212019 0.0182489  0.02647195\n",
      " 0.03378203 0.10460341 0.02170529 0.07348379 0.09113725 0.0198036\n",
      " 0.07228469 0.0227841  0.04486036 0.02156649 0.02594463 0.07672265]\n",
      "Coeficiente de determinación (R^2) de las predicciones: 0.552785028553257\n"
     ]
    }
   ],
   "source": [
    "# Algortimo de Regresión Múltiple con Random Forest\n",
    "!pip install --upgrade scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from datetime import datetime\n",
    "\n",
    "fecha_actual = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "archivo = f'datos_{fecha_actual}_ia.csv'\n",
    "\n",
    "def aplicar_modelo_regresion(csv_file):\n",
    "    # Cargar datos desde el archivo CSV\n",
    "    datos = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Dividir los datos en características (X) y etiquetas (y) para la regresión\n",
    "    X_regresion = datos.iloc[:, :-1]  # Selecciona todas las filas y todas las columnas excepto la última\n",
    "    y_regresion = datos.iloc[:, -1] # Selecciona todas las filas y la última columna\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba para regresión\n",
    "    X_train_regresion, X_test_regresion, y_train_regresion, y_test_regresion = train_test_split(X_regresion, y_regresion, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Inicializar y entrenar el modelo de regresión múltiple con Random Forest\n",
    "    modelo_regresion = RandomForestRegressor(random_state=42)\n",
    "    modelo_regresion.fit(X_train_regresion, y_train_regresion)\n",
    "\n",
    "    # Evaluar el rendimiento del modelo de regresión\n",
    "    puntuacion_regresion = modelo_regresion.score(X_test_regresion, y_test_regresion)\n",
    "    \n",
    "    # Realizar predicciones en el conjunto de prueba\n",
    "    predicciones = modelo_regresion.predict(X_test_regresion)\n",
    "    \n",
    "    # Calcular el Error Cuadrático Medio (ECM)\n",
    "    ecm = mean_squared_error(y_test_regresion, predicciones)\n",
    "\n",
    "    # Calcular el Error Absoluto Medio (EAM)\n",
    "    eam = mean_absolute_error(y_test_regresion, predicciones)\n",
    "\n",
    "    # Características más importantes (importancia de las características)\n",
    "    importancias_caracteristicas = modelo_regresion.feature_importances_\n",
    "    \n",
    "    # Coeficiente de determinación R2 \n",
    "    r2 = r2_score(y_test_regresion, predicciones)\n",
    "    \n",
    "    return puntuacion_regresion, predicciones, y_train_regresion, y_test_regresion, X_train_regresion, X_test_regresion, ecm, eam, importancias_caracteristicas, r2\n",
    "\n",
    "# Aplicar modelo regresión\n",
    "puntuacion_regresion, predicciones, y_train_regresion, y_test_regresion, X_train_regresion, X_test_regresion, ecm, eam, importancias_caracteristicas, r2 = aplicar_modelo_regresion(archivo)\n",
    "\n",
    "# Mostrar las predicciones y la puntuacion\n",
    "print(\"Puntuación del modelo de regresión múltiple (Random Forest):\", puntuacion_regresion)\n",
    "print(\"Parámetros de entrada:\\n\", X_test_regresion)\n",
    "print(\"Predicciones del modelo de regresión múltiple (Random Forest):\\n\", predicciones)\n",
    "print(\"Error Cuadrático Medio (ECM):\", ecm)\n",
    "print(\"Error Absoluto Medio (EAM):\", eam)\n",
    "print(\"Importancia de las características:\", importancias_caracteristicas)\n",
    "print(\"Coeficiente de determinación (R^2) de las predicciones:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in c:\\users\\anune\\anaconda3\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\anune\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.17.3 in c:\\users\\anune\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.5.0 in c:\\users\\anune\\anaconda3\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=1.1.1 in c:\\users\\anune\\anaconda3\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Parmetros de entrada:\n",
      "               mf         M           t             p           LHV        bpr  \\\n",
      "521  1383.299341  0.394352  283.614915  86302.984076  4.303808e+07   9.701351   \n",
      "737  1415.262118  0.383073  268.621519  86889.983840  3.994584e+07  10.076256   \n",
      "740  1473.049259  0.381253  280.708807  92496.954307  4.431118e+07   9.653684   \n",
      "660  1449.448941  0.401908  280.956805  90660.513194  4.360290e+07   9.360587   \n",
      "411  1454.161152  0.398929  285.151774  88737.468425  4.617217e+07   9.348216   \n",
      "..           ...       ...         ...           ...           ...        ...   \n",
      "408  1404.442077  0.415226  273.660916  88729.896648  4.034315e+07   9.507704   \n",
      "332  1490.071900  0.409244  284.929797  92650.925686  4.145547e+07   9.415299   \n",
      "208  1399.607068  0.383402  289.119347  91521.039806  4.623200e+07   9.403146   \n",
      "613  1464.611219  0.415987  269.594861  94166.511075  4.227834e+07  10.048646   \n",
      "78   1485.308093  0.413878  276.349533  92701.066544  4.271026e+07   9.747151   \n",
      "\n",
      "       eta_fn    eta_c1    eta_c2    eta_t1    eta_t2     eta_n    eta_cc  \\\n",
      "521  0.963630  0.886648  0.881578  0.922325  0.927238  0.986601  1.003271   \n",
      "737  0.934071  0.907229  0.927913  0.866910  0.895340  0.915898  0.978774   \n",
      "740  0.932378  0.892028  0.881119  0.884737  0.889713  0.921064  0.984128   \n",
      "660  0.960129  0.891352  0.886317  0.893067  0.901779  0.944661  0.978948   \n",
      "411  0.933389  0.870134  0.884853  0.860949  0.911880  0.925777  0.924109   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "408  0.891178  0.870885  0.846246  0.850074  0.887998  0.917611  0.995176   \n",
      "332  0.893153  0.861156  0.890744  0.905747  0.919978  0.918864  0.933753   \n",
      "208  0.958771  0.895247  0.930635  0.929590  0.900631  0.914216  0.922742   \n",
      "613  0.877311  0.894907  0.851061  0.868792  0.864111  0.974971  0.924245   \n",
      "78   0.902887  0.890107  0.915485  0.860917  0.908506  0.913679  0.961482   \n",
      "\n",
      "         PI_i     PI_fn     PI_c1      PI_c2     PI_cc  Puntuación iteración  \n",
      "521  0.997500  1.608085  1.566424  10.145176  0.962016                   6.1  \n",
      "737  0.983602  1.531414  1.521357   9.502534  0.941610                   3.7  \n",
      "740  1.021337  1.549908  1.560833   9.971984  1.026410                   7.0  \n",
      "660  1.009998  1.525464  1.489591   9.596623  1.007121                   7.3  \n",
      "411  1.027537  1.585334  1.517542   9.925869  0.985114                   5.8  \n",
      "..        ...       ...       ...        ...       ...                   ...  \n",
      "408  0.999180  1.584567  1.566235  10.006203  1.025470                   4.9  \n",
      "332  0.993903  1.572064  1.492983   9.915835  0.961731                   6.7  \n",
      "208  1.027439  1.530471  1.509612  10.149823  0.985325                   6.7  \n",
      "613  0.996423  1.576506  1.598817   9.920193  0.984419                   1.0  \n",
      "78   1.028158  1.605247  1.481093   9.977321  1.010458                   5.5  \n",
      "\n",
      "[200 rows x 19 columns]\n",
      "Predicciones de clasificación:\n",
      " ['Bien' 'Deficiente' 'Notable' 'Notable' 'Bien' 'Bien' 'Notable' 'Bien'\n",
      " 'Bien' 'Deficiente' 'Deficiente' 'Deficiente' 'Bien' 'Bien' 'Notable'\n",
      " 'Notable' 'Deficiente' 'Notable' 'Deficiente' 'Sobresaliente' 'Bien'\n",
      " 'Bien' 'Deficiente' 'Notable' 'Deficiente' 'Bien' 'Deficiente'\n",
      " 'Deficiente' 'Notable' 'Deficiente' 'Bien' 'Bien' 'Bien' 'Sobresaliente'\n",
      " 'Notable' 'Notable' 'Notable' 'Sobresaliente' 'Deficiente' 'Bien'\n",
      " 'Deficiente' 'Bien' 'Bien' 'Bien' 'Notable' 'Sobresaliente' 'Deficiente'\n",
      " 'Notable' 'Bien' 'Deficiente' 'Deficiente' 'Bien' 'Sobresaliente' 'Bien'\n",
      " 'Bien' 'Bien' 'Deficiente' 'Deficiente' 'Bien' 'Notable' 'Notable' 'Bien'\n",
      " 'Bien' 'Bien' 'Deficiente' 'Bien' 'Notable' 'Notable' 'Bien' 'Bien'\n",
      " 'Bien' 'Bien' 'Bien' 'Sobresaliente' 'Notable' 'Deficiente' 'Deficiente'\n",
      " 'Sobresaliente' 'Deficiente' 'Bien' 'Deficiente' 'Notable' 'Bien'\n",
      " 'Notable' 'Deficiente' 'Bien' 'Bien' 'Deficiente' 'Notable' 'Deficiente'\n",
      " 'Notable' 'Deficiente' 'Bien' 'Deficiente' 'Notable' 'Bien' 'Bien'\n",
      " 'Notable' 'Notable' 'Notable' 'Notable' 'Notable' 'Notable' 'Bien'\n",
      " 'Deficiente' 'Deficiente' 'Bien' 'Deficiente' 'Deficiente' 'Notable'\n",
      " 'Notable' 'Notable' 'Bien' 'Notable' 'Deficiente' 'Notable' 'Notable'\n",
      " 'Bien' 'Bien' 'Deficiente' 'Deficiente' 'Notable' 'Notable' 'Bien'\n",
      " 'Deficiente' 'Bien' 'Deficiente' 'Bien' 'Deficiente' 'Bien' 'Deficiente'\n",
      " 'Bien' 'Notable' 'Deficiente' 'Deficiente' 'Notable' 'Deficiente' 'Bien'\n",
      " 'Notable' 'Notable' 'Notable' 'Deficiente' 'Bien' 'Bien' 'Bien'\n",
      " 'Deficiente' 'Bien' 'Bien' 'Bien' 'Bien' 'Deficiente' 'Deficiente'\n",
      " 'Notable' 'Deficiente' 'Bien' 'Bien' 'Notable' 'Deficiente' 'Deficiente'\n",
      " 'Bien' 'Bien' 'Bien' 'Bien' 'Bien' 'Bien' 'Deficiente' 'Bien' 'Notable'\n",
      " 'Notable' 'Bien' 'Bien' 'Bien' 'Bien' 'Bien' 'Deficiente' 'Deficiente'\n",
      " 'Bien' 'Bien' 'Bien' 'Bien' 'Notable' 'Deficiente' 'Bien' 'Bien'\n",
      " 'Deficiente' 'Notable' 'Bien' 'Sobresaliente' 'Deficiente' 'Notable'\n",
      " 'Deficiente' 'Deficiente' 'Notable' 'Bien' 'Deficiente' 'Deficiente'\n",
      " 'Bien' 'Bien' 'Deficiente' 'Bien']\n",
      "Exactitud: 0.98\n",
      "Precisión: [0.2  0.98 1.  ]\n",
      "Recall: [1.   0.98 0.  ]\n",
      "F1-Score: 0.7810868869692399\n",
      "Matriz de Confusión:\n",
      " [[82  0  0  0  0]\n",
      " [ 0 57  0  0  0]\n",
      " [ 0  3  0  0  0]\n",
      " [ 0  0  0 49  0]\n",
      " [ 0  0  0  1  8]]\n",
      "AUC-ROC: {0: 1.0, 1: 0.9895104895104896, 2: 0.5, 3: 0.9966887417218543, 4: 0.9444444444444444}\n",
      "Curva ROC - FPR: {0: array([0., 0., 1.]), 1: array([0.        , 0.02097902, 1.        ]), 2: array([0., 1.]), 3: array([0.        , 0.00662252, 1.        ]), 4: array([0., 0., 1.])}\n",
      "Curva ROC - TPR: {0: array([0., 1., 1.]), 1: array([0., 1., 1.]), 2: array([0., 1.]), 3: array([0., 1., 1.]), 4: array([0.        , 0.88888889, 1.        ])}\n"
     ]
    }
   ],
   "source": [
    "# Algoritmo de clasificación con Random Forest\n",
    "!pip install --upgrade scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc, precision_recall_curve\n",
    "from datetime import datetime\n",
    "\n",
    "fecha_actual = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "archivo = f'datos_{fecha_actual}_ia_clasif.csv'\n",
    "    \n",
    "def aplicar_modelo_clasificacion(csv_file):\n",
    "    # Cargar datos desde el archivo CSV\n",
    "    datos = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Dividir los datos en características (X) y etiquetas (y) para la clasificación\n",
    "    X_clasificacion = datos.iloc[:, :-1]  # Selecciona todas las filas y todas las columnas excepto la última\n",
    "    y_clasificacion = datos.iloc[:, -1]   # Selecciona todas las filas y la última columna\n",
    "    \n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba para clasificación\n",
    "    X_train_clasificacion, X_test_clasificacion, y_train_clasificacion, y_test_clasificacion = train_test_split(X_clasificacion, y_clasificacion, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Inicializar y entrenar el modelo de clasificación de bosque aleatorio\n",
    "    modelo_clasificacion = RandomForestClassifier()\n",
    "    modelo_clasificacion.fit(X_train_clasificacion, y_train_clasificacion)\n",
    "\n",
    "    # Realizar predicciones y evaluar el rendimiento del modelo de clasificación\n",
    "    predicciones_clasificacion = modelo_clasificacion.predict(X_test_clasificacion)\n",
    "    exactitud = accuracy_score(y_test_clasificacion, predicciones_clasificacion)\n",
    "    matriz_confusion = confusion_matrix(y_test_clasificacion, predicciones_clasificacion)\n",
    "    precision = precision_score(y_test_clasificacion, predicciones_clasificacion, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test_clasificacion, predicciones_clasificacion, average='macro')\n",
    "    f1 = f1_score(y_test_clasificacion, predicciones_clasificacion, average='macro')\n",
    "    # fpr, tpr, _ = roc_curve(y_test_clasificacion, predicciones_clasificacion)\n",
    "    # auc_roc = roc_auc_score(y_test_clasificacion, predicciones_clasificacion)\n",
    "    # precision, recall, thresholds = precision_recall_curve(y_test_clasificacion, predicciones_clasificacion)\n",
    "    \n",
    "    # Convertir las etiquetas a formato binario\n",
    "    y_test_bin = label_binarize(y_test_clasificacion, classes=np.unique(y_test_clasificacion))\n",
    "    predicciones_bin = label_binarize(predicciones_clasificacion, classes=np.unique(y_test_clasificacion))\n",
    "\n",
    "    # Calcular la curva precision-recall y AUC-PR para cada clase individualmente\n",
    "    precision, recall, _ = precision_recall_curve(y_test_bin.ravel(), predicciones_bin.ravel())\n",
    "    auc_pr = auc(recall, precision)\n",
    "    \n",
    "    # Calcular la curva ROC y el AUC-ROC para cada clase individualmente\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    auc_roc = dict()\n",
    "    n_classes = y_test_bin.shape[1]\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], predicciones_bin[:, i])\n",
    "        auc_roc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    return predicciones_clasificacion, exactitud, precision, recall, f1, matriz_confusion, auc_roc, fpr, tpr, X_train_clasificacion, X_test_clasificacion, y_train_clasificacion, y_test_clasificacion\n",
    "\n",
    "# Aplicar modelo clasificación\n",
    "predicciones_clasificacion, exactitud, precision, recall, f1, matriz_confusion, auc_roc, fpr, tpr, X_train_clasificacion, X_test_clasificacion, y_train_clasificacion, y_test_clasificacion = aplicar_modelo_clasificacion(archivo)\n",
    "\n",
    "# Mostrar las métricas\n",
    "print(\"Parmetros de entrada:\\n\", X_test_clasificacion)\n",
    "print(\"Predicciones de clasificación:\\n\", predicciones_clasificacion)\n",
    "print(\"Exactitud:\", exactitud)\n",
    "print(\"Precisión:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"Matriz de Confusión:\\n\", matriz_confusion)\n",
    "print(\"AUC-ROC:\", auc_roc)\n",
    "print(\"Curva ROC - FPR:\", fpr)\n",
    "print(\"Curva ROC - TPR:\", tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 1.0\n",
      "Precisión: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "Clasificación: ['Bien' 'Deficiente' 'Notable' 'Notable' 'Bien' 'Bien' 'Notable' 'Bien'\n",
      " 'Bien' 'Deficiente' 'Deficiente' 'Deficiente' 'Bien' 'Bien' 'Notable'\n",
      " 'Notable' 'Muy deficiente' 'Notable' 'Deficiente' 'Sobresaliente' 'Bien'\n",
      " 'Bien' 'Deficiente' 'Notable' 'Deficiente' 'Bien' 'Deficiente'\n",
      " 'Deficiente' 'Notable' 'Deficiente' 'Bien' 'Bien' 'Bien' 'Sobresaliente'\n",
      " 'Notable' 'Notable' 'Notable' 'Sobresaliente' 'Deficiente' 'Bien'\n",
      " 'Deficiente' 'Bien' 'Bien' 'Bien' 'Notable' 'Sobresaliente' 'Deficiente'\n",
      " 'Notable' 'Bien' 'Deficiente' 'Deficiente' 'Bien' 'Sobresaliente' 'Bien'\n",
      " 'Bien' 'Bien' 'Deficiente' 'Deficiente' 'Bien' 'Notable' 'Notable' 'Bien'\n",
      " 'Bien' 'Bien' 'Deficiente' 'Bien' 'Notable' 'Notable' 'Bien' 'Bien'\n",
      " 'Bien' 'Bien' 'Bien' 'Sobresaliente' 'Notable' 'Deficiente' 'Deficiente'\n",
      " 'Sobresaliente' 'Deficiente' 'Bien' 'Deficiente' 'Notable' 'Bien'\n",
      " 'Notable' 'Muy deficiente' 'Bien' 'Bien' 'Deficiente' 'Notable'\n",
      " 'Deficiente' 'Notable' 'Deficiente' 'Bien' 'Deficiente' 'Notable' 'Bien'\n",
      " 'Bien' 'Notable' 'Notable' 'Notable' 'Notable' 'Notable' 'Notable' 'Bien'\n",
      " 'Deficiente' 'Deficiente' 'Bien' 'Deficiente' 'Deficiente' 'Notable'\n",
      " 'Notable' 'Notable' 'Bien' 'Notable' 'Deficiente' 'Notable' 'Notable'\n",
      " 'Bien' 'Bien' 'Deficiente' 'Deficiente' 'Notable' 'Notable' 'Bien'\n",
      " 'Deficiente' 'Bien' 'Deficiente' 'Bien' 'Deficiente' 'Bien' 'Deficiente'\n",
      " 'Bien' 'Notable' 'Deficiente' 'Deficiente' 'Notable' 'Deficiente' 'Bien'\n",
      " 'Notable' 'Notable' 'Notable' 'Deficiente' 'Bien' 'Bien' 'Bien'\n",
      " 'Deficiente' 'Bien' 'Bien' 'Bien' 'Bien' 'Deficiente' 'Deficiente'\n",
      " 'Notable' 'Deficiente' 'Bien' 'Bien' 'Notable' 'Deficiente' 'Deficiente'\n",
      " 'Bien' 'Bien' 'Bien' 'Bien' 'Bien' 'Bien' 'Deficiente' 'Bien' 'Notable'\n",
      " 'Notable' 'Bien' 'Bien' 'Bien' 'Bien' 'Bien' 'Deficiente' 'Deficiente'\n",
      " 'Bien' 'Bien' 'Bien' 'Bien' 'Notable' 'Deficiente' 'Bien' 'Bien'\n",
      " 'Deficiente' 'Notable' 'Bien' 'Sobresaliente' 'Deficiente' 'Notable'\n",
      " 'Deficiente' 'Deficiente' 'Sobresaliente' 'Bien' 'Deficiente'\n",
      " 'Deficiente' 'Bien' 'Bien' 'Muy deficiente' 'Bien']\n"
     ]
    }
   ],
   "source": [
    "# Tree decision classifier\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from datetime import datetime\n",
    "\n",
    "fecha_actual = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "archivo = f'datos_{fecha_actual}_ia_clasif.csv'\n",
    "\n",
    "def aplicar_arbol_clasificacion(csv_file):\n",
    "    # Cargar datos desde el archivo CSV\n",
    "    datos = pd.read_csv(csv_file)\n",
    "\n",
    "    # Cargar el conjunto de datos de ejemplo (iris dataset)\n",
    "    X = datos.iloc[:, :-1]  # Todas las filas, todas las columnas excepto la última\n",
    "    y = datos.iloc[:, -1]   # Todas las filas, sólo la última columna\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Inicializar el clasificador de árbol de decisión\n",
    "    clf = DecisionTreeClassifier()\n",
    "\n",
    "    # Entrenar el modelo utilizando el conjunto de entrenamiento\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predecir las etiquetas para el conjunto de prueba\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calcular la precisión del modelo\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    return accuracy, precision, recall, f1, y_pred\n",
    "\n",
    "# Aplicar árbol de clasificacion\n",
    "accuracy, precision, recall, f1, y_pred = aplicar_arbol_clasificacion(archivo)\n",
    "\n",
    "# Mostrar las métricas\n",
    "print(\"Precisión del modelo:\", accuracy)\n",
    "print(\"Precisión:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Clasificación:\", y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
